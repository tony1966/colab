{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_learning_illustrated_ch10_AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOfhSIQi6JxBNt1qbvbXv7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tony1966/colab/blob/main/deep_learning_illustrated_ch10_AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU654qOv69fq",
        "outputId": "68e3a72b-2827-4de9-efa1-57b206e6ab8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 33.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 34.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30 kB 39.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 33.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 107 kB 30.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=387f65ae26eb86a536b6ffc3e6ad9d88205507f16f683cbf1a6467e5c0b5701c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tflearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential  \n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization   \n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten \n",
        "import tflearn.datasets.oxflower17 as oxflower17"
      ],
      "metadata": {
        "id": "7fN9tz0yCt0F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y=oxflower17.load_data(one_hot=True)"
      ],
      "metadata": {
        "id": "nOG9GwTyBOhU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#第一個卷積區塊\n",
        "model=Sequential()\n",
        "model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4),\n",
        "         activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "#第二個卷積區塊\n",
        "model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "#第三個卷積區塊\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "#密集層\n",
        "model.add(Flatten())       \n",
        "model.add(Dense(4096, activation='tanh'))   \n",
        "model.add(Dropout(0.5))   \n",
        "model.add(Dense(4096, activation='tanh')) \n",
        "model.add(Dropout(0.5))\n",
        "#輸出層\n",
        "model.add(Dense(17, activation='softmax'))"
      ],
      "metadata": {
        "id": "4FIAvDWgBZV4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rE1U8Q8hwkP",
        "outputId": "f1f22d67-29c8-4ca7-a898-6021e86391ad"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_13 (Conv2D)          (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 26, 26, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 26, 26, 96)       384       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 22, 22, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 10, 10, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 10, 10, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 6, 6, 384)         885120    \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 4, 4, 384)         1327488   \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 1, 1, 384)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 1, 1, 384)        1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 384)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4096)              1576960   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 17)                69649     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,883,153\n",
            "Trainable params: 21,881,681\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LgQX_KV1lPjN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, Y, batch_size=64, epochs=100, verbose=1, \n",
        "          validation_split=0.1, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVO6LHlzmZV4",
        "outputId": "99eee3ce-0908-47e4-f674-f13de53181e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 1224 samples, validate on 136 samples\n",
            "Epoch 1/100\n",
            "1224/1224 [==============================] - ETA: 0s - loss: 4.4765 - acc: 0.2206"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1224/1224 [==============================] - 74s 60ms/sample - loss: 4.4765 - acc: 0.2206 - val_loss: 8.6019 - val_acc: 0.0662\n",
            "Epoch 2/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 3.2914 - acc: 0.2590 - val_loss: 5.2090 - val_acc: 0.0956\n",
            "Epoch 3/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 3.1957 - acc: 0.2369 - val_loss: 4.1489 - val_acc: 0.1691\n",
            "Epoch 4/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.6067 - acc: 0.3137 - val_loss: 6.7511 - val_acc: 0.1691\n",
            "Epoch 5/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.6182 - acc: 0.3211 - val_loss: 3.0808 - val_acc: 0.1912\n",
            "Epoch 6/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.2560 - acc: 0.3930 - val_loss: 2.7363 - val_acc: 0.2721\n",
            "Epoch 7/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.2944 - acc: 0.3881 - val_loss: 2.6362 - val_acc: 0.2868\n",
            "Epoch 8/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.2316 - acc: 0.4052 - val_loss: 4.3058 - val_acc: 0.2132\n",
            "Epoch 9/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.2326 - acc: 0.4265 - val_loss: 2.9403 - val_acc: 0.3382\n",
            "Epoch 10/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.1396 - acc: 0.4387 - val_loss: 2.4521 - val_acc: 0.3897\n",
            "Epoch 11/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.9275 - acc: 0.4706 - val_loss: 2.4860 - val_acc: 0.3971\n",
            "Epoch 12/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.8516 - acc: 0.4869 - val_loss: 2.5802 - val_acc: 0.4485\n",
            "Epoch 13/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.8397 - acc: 0.4828 - val_loss: 2.2860 - val_acc: 0.4265\n",
            "Epoch 14/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.0890 - acc: 0.4649 - val_loss: 1.9406 - val_acc: 0.4926\n",
            "Epoch 15/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.7981 - acc: 0.4886 - val_loss: 2.5606 - val_acc: 0.4559\n",
            "Epoch 16/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.7787 - acc: 0.5139 - val_loss: 3.1249 - val_acc: 0.3750\n",
            "Epoch 17/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.7248 - acc: 0.5123 - val_loss: 3.1153 - val_acc: 0.3235\n",
            "Epoch 18/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 2.0049 - acc: 0.4935 - val_loss: 2.8482 - val_acc: 0.3824\n",
            "Epoch 19/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.7494 - acc: 0.5270 - val_loss: 2.6249 - val_acc: 0.4632\n",
            "Epoch 20/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 2.7810 - acc: 0.3243 - val_loss: 6.7281 - val_acc: 0.0662\n",
            "Epoch 21/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 2.4040 - acc: 0.3603 - val_loss: 4.1349 - val_acc: 0.1912\n",
            "Epoch 22/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.1461 - acc: 0.4183 - val_loss: 2.9670 - val_acc: 0.3382\n",
            "Epoch 23/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 2.0020 - acc: 0.4199 - val_loss: 2.9810 - val_acc: 0.2794\n",
            "Epoch 24/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.9730 - acc: 0.4477 - val_loss: 3.6041 - val_acc: 0.3382\n",
            "Epoch 25/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.9569 - acc: 0.5237 - val_loss: 2.1913 - val_acc: 0.4044\n",
            "Epoch 26/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.7243 - acc: 0.5302 - val_loss: 2.7531 - val_acc: 0.4412\n",
            "Epoch 27/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.5905 - acc: 0.5237 - val_loss: 2.1504 - val_acc: 0.4632\n",
            "Epoch 28/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.4748 - acc: 0.5842 - val_loss: 2.6986 - val_acc: 0.4191\n",
            "Epoch 29/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.6112 - acc: 0.5613 - val_loss: 3.1242 - val_acc: 0.4118\n",
            "Epoch 30/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.7763 - acc: 0.5425 - val_loss: 2.0960 - val_acc: 0.5368\n",
            "Epoch 31/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.4827 - acc: 0.5703 - val_loss: 4.0465 - val_acc: 0.3456\n",
            "Epoch 32/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.5273 - acc: 0.6046 - val_loss: 2.3334 - val_acc: 0.4632\n",
            "Epoch 33/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.4493 - acc: 0.6185 - val_loss: 2.2776 - val_acc: 0.4485\n",
            "Epoch 34/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.1250 - acc: 0.6691 - val_loss: 2.2815 - val_acc: 0.4632\n",
            "Epoch 35/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.2283 - acc: 0.6528 - val_loss: 2.4770 - val_acc: 0.5441\n",
            "Epoch 36/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.3156 - acc: 0.6405 - val_loss: 2.2229 - val_acc: 0.5441\n",
            "Epoch 37/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 1.1401 - acc: 0.6716 - val_loss: 1.9500 - val_acc: 0.5588\n",
            "Epoch 38/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.9664 - acc: 0.7034 - val_loss: 1.7603 - val_acc: 0.5809\n",
            "Epoch 39/100\n",
            "1224/1224 [==============================] - 74s 60ms/sample - loss: 1.0520 - acc: 0.6855 - val_loss: 2.9422 - val_acc: 0.4706\n",
            "Epoch 40/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.0889 - acc: 0.6830 - val_loss: 1.9396 - val_acc: 0.5956\n",
            "Epoch 41/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.1893 - acc: 0.6806 - val_loss: 2.2596 - val_acc: 0.5956\n",
            "Epoch 42/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.1665 - acc: 0.6822 - val_loss: 2.4887 - val_acc: 0.5662\n",
            "Epoch 43/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 1.1644 - acc: 0.6985 - val_loss: 2.0137 - val_acc: 0.5956\n",
            "Epoch 44/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.8348 - acc: 0.7631 - val_loss: 2.4789 - val_acc: 0.5147\n",
            "Epoch 45/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.8985 - acc: 0.7606 - val_loss: 1.5301 - val_acc: 0.6765\n",
            "Epoch 46/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.8158 - acc: 0.7761 - val_loss: 1.5185 - val_acc: 0.6985\n",
            "Epoch 47/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.7394 - acc: 0.7925 - val_loss: 1.6973 - val_acc: 0.6103\n",
            "Epoch 48/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.7585 - acc: 0.7712 - val_loss: 2.2617 - val_acc: 0.5515\n",
            "Epoch 49/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.7606 - acc: 0.7958 - val_loss: 2.7456 - val_acc: 0.5809\n",
            "Epoch 50/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.5706 - acc: 0.8162 - val_loss: 2.2723 - val_acc: 0.5588\n",
            "Epoch 51/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.5670 - acc: 0.8276 - val_loss: 2.0571 - val_acc: 0.6618\n",
            "Epoch 52/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.7512 - acc: 0.7851 - val_loss: 1.8459 - val_acc: 0.6691\n",
            "Epoch 53/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.8522 - acc: 0.7663 - val_loss: 2.0038 - val_acc: 0.6250\n",
            "Epoch 54/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.5674 - acc: 0.8260 - val_loss: 1.8304 - val_acc: 0.6544\n",
            "Epoch 55/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.6451 - acc: 0.8080 - val_loss: 2.4947 - val_acc: 0.6471\n",
            "Epoch 56/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.4526 - acc: 0.8489 - val_loss: 1.8566 - val_acc: 0.6765\n",
            "Epoch 57/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.5276 - acc: 0.8529 - val_loss: 2.2762 - val_acc: 0.6324\n",
            "Epoch 58/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.4282 - acc: 0.8578 - val_loss: 2.4771 - val_acc: 0.6103\n",
            "Epoch 59/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.5994 - acc: 0.8301 - val_loss: 2.6917 - val_acc: 0.5809\n",
            "Epoch 60/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.5484 - acc: 0.8431 - val_loss: 2.0485 - val_acc: 0.6765\n",
            "Epoch 61/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.5492 - acc: 0.8554 - val_loss: 2.3478 - val_acc: 0.6029\n",
            "Epoch 62/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.4891 - acc: 0.8529 - val_loss: 2.6078 - val_acc: 0.5882\n",
            "Epoch 63/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.7577 - acc: 0.7933 - val_loss: 2.9513 - val_acc: 0.5294\n",
            "Epoch 64/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.5786 - acc: 0.8366 - val_loss: 2.6115 - val_acc: 0.6029\n",
            "Epoch 65/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.4478 - acc: 0.8660 - val_loss: 3.1456 - val_acc: 0.5809\n",
            "Epoch 66/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.6109 - acc: 0.8170 - val_loss: 2.3577 - val_acc: 0.6765\n",
            "Epoch 67/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.5586 - acc: 0.8350 - val_loss: 2.9571 - val_acc: 0.5809\n",
            "Epoch 68/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.3999 - acc: 0.8799 - val_loss: 3.1459 - val_acc: 0.6176\n",
            "Epoch 69/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.4184 - acc: 0.8938 - val_loss: 2.2182 - val_acc: 0.6691\n",
            "Epoch 70/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.4530 - acc: 0.8815 - val_loss: 2.6427 - val_acc: 0.6471\n",
            "Epoch 71/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.8653 - acc: 0.7941 - val_loss: 2.1909 - val_acc: 0.6471\n",
            "Epoch 72/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.6854 - acc: 0.8211 - val_loss: 2.3958 - val_acc: 0.6912\n",
            "Epoch 73/100\n",
            "1224/1224 [==============================] - 73s 60ms/sample - loss: 0.6700 - acc: 0.8284 - val_loss: 3.9139 - val_acc: 0.4706\n",
            "Epoch 74/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.8404 - acc: 0.7990 - val_loss: 2.5624 - val_acc: 0.6103\n",
            "Epoch 75/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.5322 - acc: 0.8578 - val_loss: 3.6777 - val_acc: 0.5368\n",
            "Epoch 76/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.5468 - acc: 0.8587 - val_loss: 2.8021 - val_acc: 0.6250\n",
            "Epoch 77/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.3437 - acc: 0.8987 - val_loss: 2.3291 - val_acc: 0.6618\n",
            "Epoch 78/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.1988 - acc: 0.9355 - val_loss: 2.0892 - val_acc: 0.7279\n",
            "Epoch 79/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2230 - acc: 0.9330 - val_loss: 1.8000 - val_acc: 0.6765\n",
            "Epoch 80/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2447 - acc: 0.9355 - val_loss: 2.4745 - val_acc: 0.6103\n",
            "Epoch 81/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2254 - acc: 0.9363 - val_loss: 2.0374 - val_acc: 0.7132\n",
            "Epoch 82/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2742 - acc: 0.9216 - val_loss: 2.5758 - val_acc: 0.6471\n",
            "Epoch 83/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.3238 - acc: 0.9085 - val_loss: 2.1191 - val_acc: 0.7059\n",
            "Epoch 84/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2334 - acc: 0.9314 - val_loss: 2.0761 - val_acc: 0.7206\n",
            "Epoch 85/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2515 - acc: 0.9322 - val_loss: 3.4162 - val_acc: 0.5809\n",
            "Epoch 86/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.1490 - acc: 0.9526 - val_loss: 2.3436 - val_acc: 0.6765\n",
            "Epoch 87/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.1436 - acc: 0.9575 - val_loss: 2.6400 - val_acc: 0.6544\n",
            "Epoch 88/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.1825 - acc: 0.9436 - val_loss: 3.5828 - val_acc: 0.6324\n",
            "Epoch 89/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.1454 - acc: 0.9518 - val_loss: 2.2761 - val_acc: 0.7059\n",
            "Epoch 90/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2460 - acc: 0.9265 - val_loss: 3.0038 - val_acc: 0.6103\n",
            "Epoch 91/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.3644 - acc: 0.9060 - val_loss: 3.2218 - val_acc: 0.6324\n",
            "Epoch 92/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.3477 - acc: 0.9093 - val_loss: 2.2449 - val_acc: 0.6912\n",
            "Epoch 93/100\n",
            "1224/1224 [==============================] - 73s 59ms/sample - loss: 0.1064 - acc: 0.9624 - val_loss: 2.2859 - val_acc: 0.6691\n",
            "Epoch 94/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2512 - acc: 0.9395 - val_loss: 2.0988 - val_acc: 0.6544\n",
            "Epoch 95/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.2284 - acc: 0.9387 - val_loss: 3.3287 - val_acc: 0.6397\n",
            "Epoch 96/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.3661 - acc: 0.9167 - val_loss: 3.2564 - val_acc: 0.6618\n",
            "Epoch 97/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.6084 - acc: 0.8668 - val_loss: 4.3696 - val_acc: 0.5882\n",
            "Epoch 98/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.6327 - acc: 0.8660 - val_loss: 3.0198 - val_acc: 0.5662\n",
            "Epoch 99/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.3577 - acc: 0.9069 - val_loss: 3.1259 - val_acc: 0.6250\n",
            "Epoch 100/100\n",
            "1224/1224 [==============================] - 72s 59ms/sample - loss: 0.4413 - acc: 0.8962 - val_loss: 3.4833 - val_acc: 0.6029\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f92bd76bb90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}